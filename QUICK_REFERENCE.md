# Neuralux Quick Reference

## üöÄ Quick Start Commands

### Start Everything
```bash
make start              # Start infrastructure
cd services/llm && python service.py &  # Start LLM (with model)
aish                    # Use AI shell
```

### Check Status
```bash
make status             # Check all services
aish status            # Check from CLI
docker compose ps      # Docker services
```

### Stop Everything
```bash
make stop              # Stop infrastructure
./scripts/stop-services.sh  # Stop all including LLM
```

## üß™ Testing Commands

```bash
./test-neuralux.sh           # Run full test suite
python3 demo-without-model.py  # Test infrastructure only
pytest tests/ -v             # Run Python unit tests
make test                    # Run all tests via Makefile
```

## üì¶ Service URLs

| Service | URL | Purpose |
|---------|-----|---------|
| NATS | `nats://localhost:4222` | Message bus |
| NATS Monitor | `http://localhost:8222` | NATS monitoring |
| Redis | `redis://localhost:6379` | Cache |
| Qdrant HTTP | `http://localhost:6333` | Vector DB |
| Qdrant gRPC | `localhost:6334` | Vector DB |
| LLM Service | `http://localhost:8000` | AI API |

## üîß Common Tasks

### View Logs
```bash
docker compose logs -f              # All services
docker compose logs -f nats         # NATS only
tail -f llm-service.log            # LLM service (if backgrounded)
```

### Restart Services
```bash
make restart                        # Restart infrastructure
docker compose restart nats         # Restart specific service
```

### Clean Up
```bash
make clean                          # Clean Python cache
docker compose down -v              # Remove volumes (reset data)
```

## ü§ñ aish CLI Commands

### Interactive Mode
```bash
aish                    # Start interactive shell
> "your command here"
> /explain ps aux
> /help
> /exit
```

### Single Command
```bash
aish ask "find large files"              # Get command only
aish ask "show disk usage" --execute     # Execute directly
aish explain "tar -xzf file.tar.gz"      # Explain command
aish status                              # Check services
```

### Overlay
```bash
aish overlay                 # Launch GUI overlay (GTK4)
aish overlay --hotkey        # Enable Ctrl+Space (default) on X11; Esc hides
```

## üìÅ Important Files

### Configuration
- `.env` - Environment variables (create from .env.example)
- `docker-compose.yml` - Infrastructure services
- `packages/common/neuralux/config.py` - Python config

### Services
- `services/llm/service.py` - LLM service
- `services/llm/config.py` - LLM configuration

### Scripts
- `scripts/start-services.sh` - Start infrastructure
- `scripts/stop-services.sh` - Stop all services
- `test-neuralux.sh` - Comprehensive tests
- `demo-without-model.py` - Infrastructure demo

### Documentation
- `README.md` - Project overview
- `GETTING_STARTED.md` - Full setup guide
- `QUICKSTART.md` - 5-minute start
- `ARCHITECTURE.md` - Technical details
- `TEST_RESULTS.md` - Test report
- `plan.md` - Original project plan

## üêõ Troubleshooting

### Services Won't Start
```bash
docker compose down      # Stop everything
docker compose up -d     # Start fresh
docker compose logs      # Check logs
```

### NATS Not Connecting
```bash
curl http://localhost:8222/varz  # Check if running
docker compose restart nats      # Restart NATS
```

### Python Package Issues
```bash
pip install -e packages/common/ --force-reinstall
pip install -e packages/cli/ --force-reinstall
```

### aish Not Found
```bash
export PATH="$HOME/.local/bin:$PATH"  # Add to PATH
pip install -e packages/cli/           # Reinstall
```

### Model Not Loading
```bash
# Check model exists
ls -lh models/

# Check model path in config
cat .env | grep LLM_DEFAULT_MODEL

# Try CPU mode
export LLM_GPU_LAYERS=0
```

## üîê Git Commands

### Push to GitHub
```bash
git status                    # Check changes
git add .                     # Stage all
git commit -m "message"       # Commit
git push -u origin main       # Push
```

### View History
```bash
git log --oneline             # View commits
git diff                      # View changes
```

## üìä Monitoring

### Check Resource Usage
```bash
docker stats                           # Container resources
docker compose top                     # Processes
htop                                   # System resources
```

### Check Disk Space
```bash
docker system df                       # Docker disk usage
du -sh models/                        # Model size
du -sh ~/.cache/neuralux/             # Cache size
```

## üîë Key Directories

```
~/.config/neuralux/     # Configuration files
~/.cache/neuralux/      # Cache data
~/.local/share/neuralux/ # Application data
```

## üí° Tips

1. **First Time Setup**: Run `./test-neuralux.sh` to verify everything
2. **Model Choice**: 3B for speed, 7B+ for quality
3. **CPU Mode**: Set `LLM_GPU_LAYERS=0` if no GPU
4. **Logs**: Use `docker compose logs -f` to debug issues
5. **Updates**: `git pull` then `make restart`

## üìû Getting Help

```bash
aish --help             # CLI help
make help              # Makefile commands
docker compose --help  # Docker Compose help
pytest --help          # Test framework help
```

## üéØ Next Steps

Based on your `plan.md`:

### Phase 1 (Current)
- ‚úÖ Core infrastructure
- ‚úÖ LLM service
- ‚úÖ CLI tool
- ‚è≥ Semantic file search
- ‚è≥ Model management UI

### Phase 2 (Next)
- Vision service
- GUI overlay (Control+Space)
- Audio service (STT/TTS)
- Temporal intelligence
- System monitoring

### Phase 3 (Future)
- Gesture recognition
- Developer tools
- Media generation
- Collaboration features
- Plugin system

---

**Quick Links**:
- GitHub: https://github.com/Wylhelm/neuralux-ai-layer
- Plan: `plan.md`
- Tests: `./test-neuralux.sh`
- Demo: `python3 demo-without-model.py`

